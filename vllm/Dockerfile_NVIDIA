FROM nvidia/cuda:12.3.1-devel-ubuntu22.04

RUN --mount=type=cache,target=/var/cache/apt,sharing=locked,rw apt-get update && \
    apt-get install --no-install-recommends -y git git-lfs vim build-essential python3-dev python3-venv ninja-build && \
    rm -rf /var/lib/apt/lists/*

ARG TORCH_CUDA_ARCH_LIST
RUN --mount=type=cache,target=/root/.cache/pip,rw \
    python3 -m venv /venv && \
    . /venv/bin/activate && \
    pip install --upgrade pip wheel setuptools packaging && \
    pip install torch numpy bitsnbytes && \
    pip install git+https://github.com/vllm-project/vllm.git@main 

ARG LLM_MODEL_NAME

ENV MODEL_REPO=https://huggingface.co/$LLM_MODEL_NAME
ENV MODEL_PATH=/root/.cache/git/$LLM_MODEL_NAME

RUN --mount=type=cache,target=/root/.cache/git,rw \
    if ! cd $MODEL_PATH; then (git lfs install; git clone $MODEL_REPO $MODEL_PATH); fi

RUN mkdir -p $LLM_MODEL_NAME

RUN --mount=type=cache,target=/root/.cache/git,rw \
    cp -R $MODEL_PATH/* /$LLM_MODEL_NAME 

CMD . /venv/bin/activate && python3 -m vllm.entrypoints.openai.api_server \
    --disable-log-stats \
    --disable-log-requests \
    --gpu-memory-utilization 0.85 \
    --model $LLM_MODEL_NAME \
    --host 0.0.0.0 \
    --port $VLLM_CONT_PORT \
    --dtype half \
    --max-model-len $MAX_MODEL_LEN
# --quantization "$QUANTIZATION" \
