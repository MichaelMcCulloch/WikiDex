version: "3.3"

services:
  vllm:
    ipc: host
    build:
      context: ./vllm
      args:
        TORCH_CUDA_ARCH_LIST: ${TORCH_CUDA_ARCH_LIST:-8.6}
        MODEL_NAME: ${MODEL_NAME:-TheBloke/zephyr-7B-beta-AWQ}
        QUANTIZATION: ${QUANTIZATION:-awq}
        MAX_MODEL_LEN: ${MAX_MODEL_LEN:-8192}
    ports:
      - "${HOST_API_PORT:-5050}:${CONTAINER_API_PORT:-5050}"
    stdin_open: true
    tty: true
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              device_ids: ["0"]
              capabilities: [gpu]
  ui:
    ipc: host
    build:
      context: ./typescript
    ports:
      - "${HOST_API_PORT:-3000}:${CONTAINER_API_PORT:-3000}"
    stdin_open: true
    tty: true
  omnipedia:
    ipc: host
    build:
      context: ./rust
      args:
        TORCH_CUDA_ARCH_LIST: ${TORCH_CUDA_ARCH_LIST:-8.6}
    ports:
      - "${HOST_API_PORT:-5000}:${CONTAINER_API_PORT:-5000}"
    stdin_open: true
    tty: true
    volumes:
      - ./rust/db:/db
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              device_ids: ["0"]
              capabilities: [gpu]
  embeddings:
    ipc: host
    build:
      context: ./embeddings_service
      args:
        TORCH_CUDA_ARCH_LIST: ${TORCH_CUDA_ARCH_LIST:-8.6}
        MODEL_NAME: ${MODEL_NAME:-thenlper/gte-small}
    ports:
      - "${HOST_API_PORT:-9000}:${CONTAINER_API_PORT:-9000}"
    stdin_open: true
    tty: true
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              device_ids: ["0"]
              capabilities: [gpu]
