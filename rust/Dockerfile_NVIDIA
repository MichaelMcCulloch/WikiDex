FROM rust:1.74.1-bookworm as builder

RUN \
    --mount=type=cache,target=/var/cache/apt,sharing=locked,rw apt-get update  && \
    apt-get install -y cmake pkg-config libssl-dev liblapack-dev libblas-dev && \
    rm -rf /var/lib/apt/lists/*
WORKDIR /usr/src/omnipedia
COPY ./Cargo.toml ./Cargo.toml
COPY ./src ./src
RUN  \
    --mount=type=cache,target=/usr/src/omnipedia/target,sharing=locked,rw cargo install --path . --root ./build

FROM nvidia/cuda:12.3.1-runtime-ubuntu22.04
ARG TORCH_CUDA_ARCH_LIST="${TORCH_CUDA_ARCH_LIST}"
RUN --mount=type=cache,target=/var/cache/apt,sharing=locked,rw apt-get update  && \
    apt-get install -y pkg-config libssl-dev liblapack-dev libblas-dev libgomp1 && \
    rm -rf /var/lib/apt/lists/*
COPY --from=builder /usr/src/omnipedia/build/bin/omnipedia /usr/local/bin/omnipedia


CMD omnipedia \
    server \
    --index "${INDEX_PATH}" \
    --docstore "${DOCSTORE_PATH}" \
    --model-name "${LLM_MODEL_NAME}" \
    --host 0.0.0.0 \
    --port "${OMNIPEDIA_CONT_PORT}" \
    --embed-url "http://embeddings-nv:${EMBED_CONT_PORT}" \
    --vllm-url "http://vllm-nv:${VLLM_CONT_PORT}/v1" \
    --model-length "${MAX_MODEL_LEN}" \
    --prompt-path "${PROMPT_PATH}"